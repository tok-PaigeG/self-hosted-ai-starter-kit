name: "AI Chat Basic Example"
id: "ai-chat-basic-example"
description: "Simple AI chat interface using local Ollama for processing"
author: "Team Example"
category: "ai-chat"
created_at: "2024-01-01T00:00:00Z"
updated_at: "2024-01-01T00:00:00Z"
version: "1.0.0"
n8n_version: "latest"
tags: ["ai", "chat", "example", "ollama", "team-workflow"]
status: "example"
requirements:
  credentials:
    - name: "Local Ollama Service"
      type: "ollamaApi"
      required: true
  nodes:
    - "@n8n/n8n-nodes-langchain.chatTrigger"
    - "@n8n/n8n-nodes-langchain.chainLlm"
    - "@n8n/n8n-nodes-langchain.lmChatOllama"
  environment_variables:
    - name: "OLLAMA_HOST"
      description: "Ollama service endpoint"
      default: "ollama:11434"
      required: true
testing:
  test_data_provided: true
  validation_rules:
    - "Must respond to basic questions"
    - "Should maintain conversation context"
    - "Response time under 30 seconds"
deployment:
  auto_activate: false
  schedule: null
  webhook_enabled: true
performance:
  estimated_execution_time: "5-15 seconds"
  memory_usage: "low"
  cpu_usage: "medium"
security:
  data_privacy: "All processing local"
  external_apis: "none"
  credential_requirements: "Ollama API access only"